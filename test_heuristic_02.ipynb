{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from sympy.combinatorics import Permutation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local data_dir\n",
    "data_dir = Path(\"data\")\n",
    "\n",
    "puzzle_info = pd.read_csv(data_dir / 'puzzle_info.csv', index_col='puzzle_type')\n",
    "# Parse allowed_moves\n",
    "puzzle_info['allowed_moves'] = puzzle_info['allowed_moves'].apply(literal_eval)\n",
    "# puzzle_info_df['total_allowed_moves'] = puzzle_info_df['allowed_moves_dict'].apply(lambda x: len(x.keys()))\n",
    "puzzle_info['number_moves'] = puzzle_info['allowed_moves'].apply(lambda x: len(x.keys()))\n",
    "\n",
    "puzzles_all = pd.read_csv(data_dir / 'puzzles.csv', index_col='id')\n",
    "# Parse color states\n",
    "puzzles_all = puzzles_all.assign(\n",
    "    initial_state=lambda df: df['initial_state'].str.split(';'),\n",
    "    solution_state=lambda df: df['solution_state'].str.split(';')\n",
    ")\n",
    "\n",
    "puzzles_all['total_components'] = puzzles_all['solution_state'].apply(len)\n",
    "puzzles_all['all_unique_components'] = puzzles_all['solution_state'].apply(lambda x: np.unique(x))\n",
    "puzzles_all['unique_components'] = puzzles_all['all_unique_components'].apply(len)\n",
    "\n",
    "# load the sample_submission\n",
    "ss = pd.read_csv(data_dir / 'sample_submission.csv', index_col='id')\n",
    "ss['moves'] = ss['moves'].str.split('.')\n",
    "ss['move_count'] = ss['moves'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with puzzle 30\n",
    "puzzle_id = 30\n",
    "puzzle = puzzles_all.loc[puzzle_id]\n",
    "\n",
    "# extract initial state and final state as np.array\n",
    "initial_state = np.array(puzzle['initial_state'])\n",
    "final_state = np.array(puzzle['solution_state'])\n",
    "\n",
    "# create ditionary of allowed moves\n",
    "allowed_moves = puzzle_info.loc[puzzle['puzzle_type']]['allowed_moves']\n",
    "# create dictionary of allowed moves converting list to np.array\n",
    "allowed_moves = {k: np.array(v) for k, v in allowed_moves.items()}\n",
    "# include inverse moves\n",
    "move_key = list(allowed_moves.keys())\n",
    "for i in range(len(allowed_moves)):\n",
    "    move = allowed_moves[move_key[i]]\n",
    "    allowed_moves[f\"-{move_key[i]}\"] = np.argsort(move)\n",
    "\n",
    "\n",
    "# create reverse_states_df with distance column == 0 and state column == final state\n",
    "reverse_states_df = pd.DataFrame(columns=['distance', 'state'])\n",
    "reverse_states_df.loc[0] = [0, final_state]\n",
    "used_states = set(final_state)\n",
    "i = 1\n",
    "for k, v in allowed_moves.items():\n",
    "    new_state = final_state[v]\n",
    "    if tuple(new_state) not in used_states:\n",
    "        l = len(reverse_states_df)\n",
    "        # add info to reverse_states_df\n",
    "        reverse_states_df.loc[l] = [i, new_state]\n",
    "        # add new_state to used_states\n",
    "        used_states.add(tuple(new_state))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0: type: cube_2/2/2, unique_components: 6, moves: 2\n",
      "id 1: type: cube_2/2/2, unique_components: 6, moves: 63\n",
      "id 2: type: cube_2/2/2, unique_components: 6, moves: 62\n",
      "id 3: type: cube_2/2/2, unique_components: 6, moves: 92\n",
      "id 4: type: cube_2/2/2, unique_components: 6, moves: 70\n",
      "id 5: type: cube_2/2/2, unique_components: 6, moves: 54\n",
      "id 6: type: cube_2/2/2, unique_components: 6, moves: 68\n",
      "id 7: type: cube_2/2/2, unique_components: 6, moves: 83\n",
      "id 8: type: cube_2/2/2, unique_components: 6, moves: 98\n",
      "id 9: type: cube_2/2/2, unique_components: 6, moves: 76\n",
      "id 10: type: cube_2/2/2, unique_components: 6, moves: 66\n",
      "id 11: type: cube_2/2/2, unique_components: 6, moves: 63\n",
      "id 12: type: cube_2/2/2, unique_components: 6, moves: 72\n",
      "id 13: type: cube_2/2/2, unique_components: 6, moves: 131\n",
      "id 14: type: cube_2/2/2, unique_components: 6, moves: 96\n",
      "id 15: type: cube_2/2/2, unique_components: 6, moves: 68\n",
      "id 16: type: cube_2/2/2, unique_components: 6, moves: 63\n",
      "id 17: type: cube_2/2/2, unique_components: 6, moves: 62\n",
      "id 18: type: cube_2/2/2, unique_components: 6, moves: 89\n",
      "id 19: type: cube_2/2/2, unique_components: 6, moves: 82\n",
      "id 20: type: cube_2/2/2, unique_components: 24, moves: 112\n",
      "id 21: type: cube_2/2/2, unique_components: 24, moves: 96\n",
      "id 22: type: cube_2/2/2, unique_components: 24, moves: 63\n",
      "id 23: type: cube_2/2/2, unique_components: 24, moves: 53\n",
      "id 24: type: cube_2/2/2, unique_components: 24, moves: 99\n",
      "id 25: type: cube_2/2/2, unique_components: 6, moves: 61\n",
      "id 26: type: cube_2/2/2, unique_components: 6, moves: 93\n",
      "id 27: type: cube_2/2/2, unique_components: 6, moves: 73\n",
      "id 28: type: cube_2/2/2, unique_components: 6, moves: 83\n",
      "id 29: type: cube_2/2/2, unique_components: 6, moves: 82\n",
      "id 30: type: cube_3/3/3, unique_components: 6, moves: 300\n",
      "id 31: type: cube_3/3/3, unique_components: 6, moves: 392\n",
      "id 32: type: cube_3/3/3, unique_components: 6, moves: 268\n",
      "id 33: type: cube_3/3/3, unique_components: 6, moves: 239\n",
      "id 34: type: cube_3/3/3, unique_components: 6, moves: 304\n",
      "id 35: type: cube_3/3/3, unique_components: 6, moves: 440\n",
      "id 36: type: cube_3/3/3, unique_components: 6, moves: 267\n",
      "id 37: type: cube_3/3/3, unique_components: 6, moves: 299\n",
      "id 38: type: cube_3/3/3, unique_components: 6, moves: 237\n",
      "id 39: type: cube_3/3/3, unique_components: 6, moves: 408\n",
      "id 40: type: cube_3/3/3, unique_components: 6, moves: 259\n",
      "id 41: type: cube_3/3/3, unique_components: 6, moves: 296\n",
      "id 42: type: cube_3/3/3, unique_components: 6, moves: 208\n",
      "id 43: type: cube_3/3/3, unique_components: 6, moves: 229\n",
      "id 44: type: cube_3/3/3, unique_components: 6, moves: 602\n",
      "id 45: type: cube_3/3/3, unique_components: 6, moves: 584\n",
      "id 46: type: cube_3/3/3, unique_components: 6, moves: 327\n",
      "id 47: type: cube_3/3/3, unique_components: 6, moves: 358\n",
      "id 48: type: cube_3/3/3, unique_components: 6, moves: 242\n",
      "id 49: type: cube_3/3/3, unique_components: 6, moves: 258\n",
      "id 50: type: cube_3/3/3, unique_components: 6, moves: 238\n",
      "id 51: type: cube_3/3/3, unique_components: 6, moves: 370\n",
      "id 52: type: cube_3/3/3, unique_components: 6, moves: 479\n",
      "id 53: type: cube_3/3/3, unique_components: 6, moves: 355\n",
      "id 54: type: cube_3/3/3, unique_components: 6, moves: 230\n",
      "id 55: type: cube_3/3/3, unique_components: 6, moves: 309\n",
      "id 56: type: cube_3/3/3, unique_components: 6, moves: 285\n",
      "id 57: type: cube_3/3/3, unique_components: 6, moves: 344\n",
      "id 58: type: cube_3/3/3, unique_components: 6, moves: 282\n",
      "id 59: type: cube_3/3/3, unique_components: 6, moves: 415\n",
      "id 60: type: cube_3/3/3, unique_components: 6, moves: 251\n",
      "id 61: type: cube_3/3/3, unique_components: 6, moves: 236\n",
      "id 62: type: cube_3/3/3, unique_components: 6, moves: 385\n",
      "id 63: type: cube_3/3/3, unique_components: 6, moves: 225\n",
      "id 64: type: cube_3/3/3, unique_components: 6, moves: 429\n",
      "id 65: type: cube_3/3/3, unique_components: 6, moves: 200\n",
      "id 66: type: cube_3/3/3, unique_components: 6, moves: 250\n",
      "id 67: type: cube_3/3/3, unique_components: 6, moves: 331\n",
      "id 68: type: cube_3/3/3, unique_components: 6, moves: 298\n",
      "id 69: type: cube_3/3/3, unique_components: 6, moves: 225\n",
      "id 70: type: cube_3/3/3, unique_components: 6, moves: 205\n",
      "id 71: type: cube_3/3/3, unique_components: 6, moves: 266\n",
      "id 72: type: cube_3/3/3, unique_components: 6, moves: 327\n",
      "id 73: type: cube_3/3/3, unique_components: 6, moves: 392\n",
      "id 74: type: cube_3/3/3, unique_components: 6, moves: 408\n",
      "id 75: type: cube_3/3/3, unique_components: 6, moves: 320\n",
      "id 76: type: cube_3/3/3, unique_components: 6, moves: 382\n",
      "id 77: type: cube_3/3/3, unique_components: 6, moves: 358\n",
      "id 78: type: cube_3/3/3, unique_components: 6, moves: 257\n",
      "id 79: type: cube_3/3/3, unique_components: 6, moves: 254\n",
      "id 80: type: cube_3/3/3, unique_components: 6, moves: 372\n",
      "id 81: type: cube_3/3/3, unique_components: 6, moves: 221\n",
      "id 82: type: cube_3/3/3, unique_components: 6, moves: 251\n",
      "id 83: type: cube_3/3/3, unique_components: 6, moves: 300\n",
      "id 84: type: cube_3/3/3, unique_components: 6, moves: 260\n",
      "id 85: type: cube_3/3/3, unique_components: 6, moves: 227\n",
      "id 86: type: cube_3/3/3, unique_components: 6, moves: 265\n",
      "id 87: type: cube_3/3/3, unique_components: 6, moves: 310\n",
      "id 88: type: cube_3/3/3, unique_components: 6, moves: 209\n",
      "id 89: type: cube_3/3/3, unique_components: 6, moves: 268\n",
      "id 90: type: cube_3/3/3, unique_components: 6, moves: 277\n",
      "id 91: type: cube_3/3/3, unique_components: 6, moves: 303\n",
      "id 92: type: cube_3/3/3, unique_components: 6, moves: 216\n",
      "id 93: type: cube_3/3/3, unique_components: 6, moves: 214\n",
      "id 94: type: cube_3/3/3, unique_components: 6, moves: 317\n",
      "id 95: type: cube_3/3/3, unique_components: 6, moves: 287\n",
      "id 96: type: cube_3/3/3, unique_components: 6, moves: 425\n",
      "id 97: type: cube_3/3/3, unique_components: 6, moves: 323\n",
      "id 98: type: cube_3/3/3, unique_components: 6, moves: 292\n",
      "id 99: type: cube_3/3/3, unique_components: 6, moves: 249\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100):\n",
    "    print(f\"id {i}: type: {puzzles_all.loc[i]['puzzle_type']}, unique_components: {puzzles_all.loc[i]['unique_components']}, moves: {ss.loc[i]['move_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the state column from reverse_states_df and store it as a np.array\n",
    "reverse_states = np.array(reverse_states_df['state'].tolist())\n",
    "reverse_states.shape\n",
    "\n",
    "# perform row-wise comparison of reverse_states with final_state and sum the number of matches\n",
    "np.sum(reverse_states != final_state, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_7/jc101n2d4n79l6kv7vkhr89r0000gn/T/ipykernel_96044/35167483.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_moves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mused_states\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mreverse_states_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_states_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurrent_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mused_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/2023_12_KagglePolytopePerm/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/2023_12_KagglePolytopePerm/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_missing_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/2023_12_KagglePolytopePerm/lib/python3.11/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2237\u001b[0m                     \u001b[0;31m#  dtype.  But if we had a list or dict, then do inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m                     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/2023_12_KagglePolytopePerm/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6217\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6219\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6220\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6222\u001b[0m         \u001b[0;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# work with puzzle 30\n",
    "puzzle_id = 30\n",
    "puzzle = puzzles_all.loc[puzzle_id]\n",
    "\n",
    "# extract initial state and final state as np.array\n",
    "initial_state = np.array(puzzle['initial_state'])\n",
    "final_state = np.array(puzzle['solution_state'])\n",
    "\n",
    "# create ditionary of allowed moves\n",
    "allowed_moves = puzzle_info.loc[puzzle['puzzle_type']]['allowed_moves']\n",
    "# create dictionary of allowed moves converting list to np.array\n",
    "allowed_moves = {k: np.array(v) for k, v in allowed_moves.items()}\n",
    "# include inverse moves\n",
    "move_key = list(allowed_moves.keys())\n",
    "for i in range(len(allowed_moves)):\n",
    "    move = allowed_moves[move_key[i]]\n",
    "    allowed_moves[f\"-{move_key[i]}\"] = np.argsort(move)\n",
    "\n",
    "# create reverse_states_df with distance column == 0 and state column == final state\n",
    "reverse_states_df = pd.DataFrame(columns=['distance', 'state'])\n",
    "reverse_states_df.loc[0] = [0, final_state]\n",
    "used_states = set(final_state)\n",
    "\n",
    "max_depth = 5  # Define the maximum depth of the search\n",
    "while reverse_states_df['distance'].max() < max_depth:\n",
    "    current_depth = reverse_states_df['distance'].max()\n",
    "    states_to_expand = reverse_states_df[reverse_states_df['distance'] == current_depth]\n",
    "\n",
    "    for index, row in states_to_expand.iterrows():\n",
    "        current_state = row['state']\n",
    "        for move_name, move in allowed_moves.items():\n",
    "            new_state = current_state[move]\n",
    "            if tuple(new_state) not in used_states:\n",
    "                reverse_states_df.loc[len(reverse_states_df)] = [current_depth + 1, new_state]\n",
    "                used_states.add(tuple(new_state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of reverse states\n",
    "state_distance_dict = {tuple(row['state']): row['distance'] for _, row in reverse_states_df.iterrows()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174198"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_distance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import time\n",
    "\n",
    "def base_heuristic(intermediate_state, final_state):\n",
    "    \"\"\"\n",
    "    Calculate a base heuristic for the given state.\n",
    "    This is just a placeholder function; you should replace it with your actual heuristic logic.\n",
    "    \"\"\"\n",
    "    # Example heuristic logic (to be replaced with your specific heuristic calculation)\n",
    "    return np.sum(np.abs(intermediate_state - final_state))\n",
    "\n",
    "def get_state_distance(intermediate_state, state_distance_dict, final_state):\n",
    "    \"\"\"\n",
    "    Return the distance of the intermediate state from the final state.\n",
    "    If the state is not found, revert to the base heuristic.\n",
    "    \"\"\"\n",
    "    return state_distance_dict.get(tuple(intermediate_state), evaluate_difference(intermediate_state, final_state))\n",
    "\n",
    "def evaluate_difference(state1, state2):\n",
    "    \"\"\"\n",
    "    Count the number of positions where the values in two numpy arrays differ.\n",
    "\n",
    "    Args:\n",
    "    state1 (np.array): First state, a numpy array.\n",
    "    state2 (np.array): Second state, a numpy array.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of differing positions.\n",
    "    \"\"\"\n",
    "    if state1.shape != state2.shape:\n",
    "        raise ValueError(\"States must have the same shape.\")\n",
    "\n",
    "    # Count the number of differing elements\n",
    "    return np.sum(state1 != state2)\n",
    "\n",
    "def astar(move_dict, initial_state, final_state, state_distance_dict, \n",
    "          wildcards, max_depth=50, timeout = 180, verbose=False):\n",
    "    '''\n",
    "    A* search algorithm. Returns the path of moves to solve the puzzle.\n",
    "    Inputs:\n",
    "        move_dict: Dictionary of moves\n",
    "        initial_state: Initial state of the puzzle\n",
    "        final_state: Final state of the puzzle\n",
    "        state_distance_dict: Dictionary of states and their distances from the final state\n",
    "        wildcards: Number of wildcards allowed\n",
    "        max_depth: Maximum depth to search\n",
    "        timeout: Maximum time to search\n",
    "    Outputs:\n",
    "        path: List of moves to solve the puzzle\n",
    "        node_counter: Number of nodes visited\n",
    "        time_delta: Time elapsed\n",
    "        '''\n",
    "    \n",
    "    # Priority queue to store nodes with their f-values (g + h)\n",
    "    start_time = time.time()\n",
    "    open_set = []\n",
    "    node_counter = 1\n",
    "\n",
    "    final_state_np = np.array(final_state)\n",
    "    \n",
    "    # Use a heap to store nodes with the lowest f-value at the top in open_set\n",
    "    # heap is a list of tuples (f-value, state, path)\n",
    "    heapq.heappush(open_set, (0, initial_state, [])) \n",
    "    \n",
    "    # create closed set to store visited nodes\n",
    "    closed_set = set()\n",
    "\n",
    "    while open_set:\n",
    "        # Check for timeout\n",
    "        time_delta = time.time() - start_time\n",
    "        if time_delta > timeout:\n",
    "            print(\"Timed out.\")\n",
    "            return None, node_counter, time_delta\n",
    "        \n",
    "        # Get the node with the lowest f-value from the heap open_set\n",
    "        current_f, current_state, current_path = heapq.heappop(open_set)\n",
    "        current_state_np = np.array(current_state)\n",
    "        \n",
    "        # Check if we've reached the max depth (early termination)\n",
    "        if len(current_path) > max_depth:\n",
    "            print(\"Max depth exceeded.\")\n",
    "            return None, node_counter, time_delta\n",
    "\n",
    "        # Check if we've reached the goal and return the path, node_counter, and time_delta\n",
    "        if evaluate_difference(current_state_np, final_state_np) <= wildcards:\n",
    "            # We've achieved our goal. Return the move path.\n",
    "            return current_path, node_counter, time_delta\n",
    "\n",
    "        # Add the current state to the closed set\n",
    "        closed_set.add(tuple(current_state))\n",
    "        \n",
    "        # Add the next possible moves to the open set\n",
    "        for move_str, move in move_dict.items():\n",
    "            # apply the move permutation to the current state\n",
    "            new_state_np = current_state_np[move]\n",
    "            new_state = list(new_state_np)\n",
    "            if tuple(new_state) not in closed_set:\n",
    "                if len(current_path) < max_depth:\n",
    "                    # Add the new state to the open set tuple (f-value, state, path)\n",
    "                    # f-value = g + h\n",
    "                        # g is the number of moves taken so far plus 1\n",
    "                        # h is the heuristic score of the new state using evaluate_score\n",
    "                    # state is the new state\n",
    "                    # path is the current path plus the new move\n",
    "\n",
    "                    # # print commands\n",
    "                    # print(f\"node_counter: {node_counter}\")\n",
    "                    # print(f\"len(current_path): {len(current_path)}\")\n",
    "                    # print(f\"get_state_distance(): {get_state_distance(new_state, state_distance_dict, final_state)}\")\n",
    "                    # print(f\"new_state: {new_state}\")\n",
    "                    # print(f\"current_path: {current_path}\")\n",
    "                    if verbose and node_counter % 1000 == 0:\n",
    "                        print(f\"current_f: {current_f} and node_counter: {node_counter}\")\n",
    "                    heapq.heappush(open_set, \n",
    "                                   (len(current_path) + 1 + get_state_distance(new_state_np, state_distance_dict, final_state_np), \n",
    "                                    new_state,\n",
    "                                    current_path + [move_str]))\n",
    "                                    \n",
    "                    # Increment the node counter\n",
    "                    node_counter += 1\n",
    "    \n",
    "    # end of the while loop\n",
    "    # If no solutions are found:\n",
    "    print(\"Open set completed. No solutions.\")\n",
    "    time_delta = time.time() - start_time\n",
    "    return None, node_counter, time_delta\n",
    "\n",
    "def plot_final_path(move_dict, initial_state, final_state, path):\n",
    "    state_list = [initial_state]\n",
    "    for move in path:\n",
    "        p = move_dict.get(move)\n",
    "        state_list.append(p(state_list[-1]))\n",
    "    eval_list = [get_state_distance(state, state_distance_dict, final_state) for state in state_list]\n",
    "    plt.plot(eval_list)\n",
    "    plt.xlabel(\"Move Number\")\n",
    "    plt.ylabel(\"Heuristic Score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out.\n",
      "FAIL!!!\n",
      "puzzle_id: 31\n",
      "\tnodes: 6238447\n",
      "\ttime: 183.5936119556427\n",
      "Timed out.\n",
      "FAIL!!!\n",
      "puzzle_id: 32\n",
      "\tnodes: 6756381\n",
      "\ttime: 180.00127601623535\n",
      "Timed out.\n",
      "FAIL!!!\n",
      "puzzle_id: 33\n",
      "\tnodes: 6393048\n",
      "\ttime: 185.97042107582092\n",
      "Timed out.\n",
      "FAIL!!!\n",
      "puzzle_id: 34\n",
      "\tnodes: 6791848\n",
      "\ttime: 180.00024700164795\n"
     ]
    }
   ],
   "source": [
    "for i in range(31, 35):\n",
    "    # work with puzzle i\n",
    "    puzzle_id = i\n",
    "    puzzle = puzzles_all.loc[puzzle_id]\n",
    "\n",
    "    # # extract initial state and final state as np.array\n",
    "    # initial_state = np.array(puzzle['initial_state'])\n",
    "    # final_state = np.array(puzzle['solution_state'])\n",
    "\n",
    "    initial_state = puzzle['initial_state']\n",
    "    final_state = puzzle['solution_state']\n",
    "\n",
    "    path, nodes, time_delta = astar(allowed_moves, initial_state, final_state, state_distance_dict, \n",
    "            wildcards=0, max_depth=50, timeout = 180)\n",
    "    if path is not None:\n",
    "        print('SOLVED!')\n",
    "        print(f\"puzzle_id: {puzzle_id}\\n\\tnodes: {nodes}\\n\\ttime: {time_delta}\\n\\tpath: {path}\")\n",
    "    else:\n",
    "        print('FAIL!!!')\n",
    "        print(f\"puzzle_id: {puzzle_id}\\n\\tnodes: {nodes}\\n\\ttime: {time_delta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023_12_KagglePolytopePerm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
